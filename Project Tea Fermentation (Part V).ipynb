{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this Part, we will use the exported CSV for machine learning and train a classification model to predict tea fermentation levels. \n",
    "\n",
    "\n",
    "\n",
    "Highly recommended readings:\n",
    "1. [Important] https://scipy-lectures.org/packages/scikit-learn/index.html\n",
    "2. https://machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/\n",
    "3. https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "\n",
    "### Step 1: Import your libraries\n",
    "We will be using models from sklearn - a popular machine learning library. However, we won't import everything from sklearn and take just what we need. \n",
    "\n",
    "We'll need to import plotting libraries to plot our predictions against the ground truth (test data). \n",
    "\n",
    "Import the following:\n",
    "1. pandas\n",
    "2. matplotlib.pyplot as plt\n",
    "3. seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daani\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\daani\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\daani\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\daani\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\daani\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import the libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read the CSV you exported in Part IV\n",
    "Read the CSV containing the normalized LBP frequencies from Part IV.\n",
    "\n",
    "You should anticipate a DataFrame with:\n",
    "1. 6,000 rows\n",
    "2. 21 columns\n",
    "3. last column is named 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.432559</td>\n",
       "      <td>0.32101</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.13616</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.132538</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.107714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094076</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.086192</td>\n",
       "      <td>0.160878</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>0.132857</td>\n",
       "      <td>0.242808</td>\n",
       "      <td>0.288089</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.432559</td>\n",
       "      <td>0.32101</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.13616</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.132538</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.107714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094076</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.086192</td>\n",
       "      <td>0.160878</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>0.132857</td>\n",
       "      <td>0.242808</td>\n",
       "      <td>0.288089</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.432559</td>\n",
       "      <td>0.32101</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.13616</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.132538</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.107714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094076</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.086192</td>\n",
       "      <td>0.160878</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>0.132857</td>\n",
       "      <td>0.242808</td>\n",
       "      <td>0.288089</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.432559</td>\n",
       "      <td>0.32101</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.13616</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.132538</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.107714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094076</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.086192</td>\n",
       "      <td>0.160878</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>0.132857</td>\n",
       "      <td>0.242808</td>\n",
       "      <td>0.288089</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.432559</td>\n",
       "      <td>0.32101</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.13616</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.132538</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.107714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094076</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.086192</td>\n",
       "      <td>0.160878</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>0.132857</td>\n",
       "      <td>0.242808</td>\n",
       "      <td>0.288089</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    0         1        2         3        4         5         6  \\\n",
       "0           0  1.0  0.432559  0.32101  0.120499  0.13616  0.177072  0.132538   \n",
       "1           1  1.0  0.432559  0.32101  0.120499  0.13616  0.177072  0.132538   \n",
       "2           2  1.0  0.432559  0.32101  0.120499  0.13616  0.177072  0.132538   \n",
       "3           3  1.0  0.432559  0.32101  0.120499  0.13616  0.177072  0.132538   \n",
       "4           4  1.0  0.432559  0.32101  0.120499  0.13616  0.177072  0.132538   \n",
       "\n",
       "          7         8  ...        11        12        13        14        15  \\\n",
       "0  0.137971  0.107714  ...  0.094076  0.119433  0.086192  0.160878  0.110058   \n",
       "1  0.137971  0.107714  ...  0.094076  0.119433  0.086192  0.160878  0.110058   \n",
       "2  0.137971  0.107714  ...  0.094076  0.119433  0.086192  0.160878  0.110058   \n",
       "3  0.137971  0.107714  ...  0.094076  0.119433  0.086192  0.160878  0.110058   \n",
       "4  0.137971  0.107714  ...  0.094076  0.119433  0.086192  0.160878  0.110058   \n",
       "\n",
       "         16        17        18        19  label  \n",
       "0  0.132857  0.242808  0.288089  0.987641    NaN  \n",
       "1  0.132857  0.242808  0.288089  0.987641    NaN  \n",
       "2  0.132857  0.242808  0.288089  0.987641    NaN  \n",
       "3  0.132857  0.242808  0.288089  0.987641    NaN  \n",
       "4  0.132857  0.242808  0.288089  0.987641    NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Read the CSV\n",
    "df = pd.read_csv('lbpteaferm.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare your independent and dependent variables\n",
    "At this point, let's prepare our indepedent and dependent variables. \n",
    "\n",
    "1. Declare a variable, and assign your independent variables to it, i.e. drop \"label\" from the DataFrame\n",
    "2. Declare a variable, and assign only values from \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare your independent and dependent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Import machine learning libraries\n",
    "Time to import other libraries. We hope you've taken a look at the two articles at the start of this notebook because it'll be useful. \n",
    "\n",
    "Import the following libraries and methods:\n",
    "1. Dummyclassifier - sklearn.dummy\n",
    "2. DecisionTreeClassifier - sklearn.tree\n",
    "3. RandomForestClassifier - sklearn.ensemble\n",
    "4. confusion_matrix - sklearn.metrics\n",
    "5. train_test_split - sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Import the ML libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Split your independent and dependent variables into train and test sets\n",
    "We'll be using a 80/20 split for train and test set respectively, using the train_test_split function. Don't forget to stratify by your dependent variable as one of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Split your data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Train your DummyClassifier machine learning model\n",
    "Once you've split your data, machine learning begins. We'll start off with a DummyClassifier to set a baseline.\n",
    "\n",
    "This is what you'll need to do:\n",
    "1. Declare a variable, and store your model in it (don't forget to use brackets)\n",
    "2. Fit your training data into the instantiated DummyClassifier model\n",
    "3. Declare a variable that contains predictions from the model you just trained, using the train dataset (X_test)\n",
    "4. Print the confusion matrix that compares your prediction with the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Train your DummyClassifier and make a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Repeat Step 6 with DecisionTreeClassifier\n",
    "As expected, DummyClassifier is as good as random guessing but it provides a good baseline. \n",
    "\n",
    "Next up, do the same with DecisionTreeClassifier and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train a DecisionTreeClassifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Repeat Step 6 with RandomForestClassifier\n",
    "What...? You probably can't believe your eyes. The DecisionTreeClassifier is perfect. \n",
    "\n",
    "Why don't you give RandomForestClassifier another go? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Train a RandomForestClassifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Identify the most important features in the RandomForestClassifier\n",
    "Interesting - surely there are features that allow our RandomForest model to be so accurate. \n",
    "\n",
    "Let's break it down and extract the feature importances, and use it in conjunction with your column names to turn it into a DataFrame. \n",
    "\n",
    "![FeatureImportanceExample](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/FeatureImportance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Sort your DataFrame to find the top feature importance\n",
    "Let's see which feature contributes most to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Sort your feature importance DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Plot a boxplot to visualize the differences in the identified features\n",
    "Now that you've identified the features which contributes most to classifying the tea fermentation levels, let's plot a boxplot to visualize the differences between these features in their respective classes.\n",
    "\n",
    "We want to look at the three boxplot sets in the features that we've identified in Step 10.\n",
    "\n",
    "You'll seem something like this:\n",
    "\n",
    "![FeatureBoxplotsHue](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/FeatureBoxplotHue.png)\n",
    "\n",
    "<strong>Hint: Google \"plotting multiple boxplots in seaborn\"</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Plot boxplots of features in the three labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end\n",
    "And that's the end! We are done with both machine and deep learning aspects of our tea fermentation project.\n",
    "\n",
    "To recap, you've:\n",
    "1. Retrieved research data on tea fermentation\n",
    "2. Split the files in a structure suitable for deep learning\n",
    "3. Implemented a modified AlexNet neural network architecture\n",
    "4. Extracted local binary patterns from images \n",
    "5. Used local binary patterns as features for machine learning\n",
    "\n",
    "Go on, give yourself a pat on the back. We hope this project series has give you more confidence in coding and machine learning and deep learning. \n",
    "\n",
    "Whatever you learn here is but a tip of the iceberg, and launchpad for bigger and better things to come. Come join us in our Telegram community over at https://bit.ly/UpLevelSG and our Facebook page at https://fb.com/UpLevelSG\n",
    "\n",
    "Whatever you learn here is but a tip of the iceberg, and launchpad for bigger and better things to come."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
