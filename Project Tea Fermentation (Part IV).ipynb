{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a neural network model was tough work, and while we did well we should take the chance to use classical machine learning to see if we can achieve the same performance.\n",
    "\n",
    "1. Install scikit-image\n",
    "2. Derive local binary patterns from one image using scikit-image\n",
    "3. Derive local binary patterns from all images\n",
    "4. Create a DataFrame containing each image's LBP\n",
    "5. Export the DataFrame into a CSV in Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install scikit-image\n",
    "scikit-image is like scikit-learn, but for images. It contains a suite of methods to extract information from images, and in our case - local binary patterns (LBP).\n",
    "\n",
    "\n",
    "1. https://towardsdatascience.com/face-recognition-how-lbph-works-90ec258c3d6b\n",
    "2. https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_local_binary_pattern.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.5.1.48-cp37-cp37m-win_amd64.whl (41.2 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\daani\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from opencv-contrib-python) (1.18.1)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.5.1.48\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install scikit-image\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LBP extraction on a single image\n",
    "Before we do LBP extract on all of the images, let's give LBP a try on a single image.\n",
    "\n",
    "We will aim to:\n",
    "1. select one image\n",
    "2. turn it greyscale\n",
    "3. extract the local binary pattern\n",
    "4. flatten the resulting array\n",
    "5. normalize the values\n",
    "6. plot a histogram\n",
    "7. extract the binned histogram values\n",
    "\n",
    "If all goes well, this is what you'll see for Steps 1-6:\n",
    "\n",
    "![LBPExtraction](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/LBPExtractionProcess.png)\n",
    "\n",
    "\n",
    "### Step 2: Import libraries\n",
    "We'll need to import:\n",
    "1. local_binary_pattern from skimage.features\n",
    "2. cv2\n",
    "3. matplotlib.pyplot as plt\n",
    "4. matplotlib.image as mpimg\n",
    "5. numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import the libraries\n",
    "from skimage.feature import local_binary_pattern\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Select the path of a random image in your dataset\n",
    "Remember we told you not to delete the original folders in your Google Drive after splitting? Pick a random image in any of the <strong>original</strong> three tea folders. \n",
    "\n",
    "Any one of them works, since we just want to test it.\n",
    "\n",
    "Declare a variable to store that path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Get the path of a random image in your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualize the image\n",
    "We'll be using the matplotlib.image library to visualize the library.\n",
    "\n",
    "<strong>Hint: Google \"matplotlib visualize image\"</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize the image you've chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Convert the image to greyscale and vizualize it\n",
    "Use cv2 library to convert your image to greyscale, and then use matplotlib.image library to image it. \n",
    "\n",
    "That said, there are a few ways to image your grayscaled image, including cv2 itself. Try different methods to display your image. \n",
    "\n",
    "<font color = 'red'>Just make sure you have your image converted to gray scale using cv2.</font>\n",
    "\n",
    "Note: When you use imshow from matplotlib library, make sure your cmap parameter has 'gray' in it. Otherwise you'll get a fake color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5a: Convert your image into grayscale and save it in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5b: Visualize the grayscale image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Perform local binary pattern extraction from your image in Step 5\n",
    "We will then extract the local binary pattern from the grayscale image using the local_binary_pattern function.\n",
    "\n",
    "Save the results into a variable.\n",
    "\n",
    "Here are the parameters you should take note of as well:\n",
    "1. n_points - 8\n",
    "2. radius - 3\n",
    "\n",
    "When you've extracted the LBP, you will get an array that is something like this (this is just an example):\n",
    "\n",
    "![LBPArrayExample](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/LBPArrayExample.png)\n",
    "\n",
    "The .shape of the array is (183, 243).\n",
    "\n",
    "<strong>Hint: The documentation for local_binary_pattern will help you.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Get the LBP of the grayscale image from Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Flatten your array using .ravel() for normalization\n",
    "Currently, the array is 183 x 243. However, if you're going to plot the distribution of values in a histogram, you'll need two things:\n",
    "1. Flatten the array into a 1D array of length 44469 (183 times 243)\n",
    "2. Divide all items in the 1D array by the max value for normalization\n",
    "\n",
    "Here's what we expect to see:\n",
    "\n",
    "![TransformingDataForHistogram](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/TransformingDataForHistogram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7a: Use the .ravel() method on the array you got from Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7b: Divide the resulting array with the largest value in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Plot your normalized array in a histogram\n",
    "Plot your array in a histogram to see something like the LBP histogram above.\n",
    "\n",
    "Make sure you have 20 bins as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Plot a histogram using your normalized 1D array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Use numpy.histogram() to get the histogram data\n",
    "Currently, we have a 1D array of length 44469. However, what the histogram was good at was binning the the values into buckets.\n",
    "\n",
    "We will next want to retrieve the relative frequency of the bins as a feature to build our DataFrame. The reason is because the frequencies of the normalized LBPs are presumably distinct for different tea fermentation levels. \n",
    "\n",
    "![NormalizedHistogramFrequency](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/NormalizedHistogramFrequency.png)\n",
    "\n",
    "What we need to do next is to:\n",
    "1. Use numpy.histogram() to get the frequency of the 20-bin values \n",
    "2. Take only the frequency of the bins\n",
    "3. Normalize the frequency of the bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Get the normalized frequency of the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform LBP extraction on the entire dataset\n",
    "Now that you've practised performing LBP extraction on one single image, you'll have to repeat Steps 5-9 for the entire image dataset. \n",
    "\n",
    "Once we have a list of the normalized frequencies of the LBP patterns, we can then turn the entire list of arrays into a DataFrame. \n",
    "\n",
    "![ListOfArraysToDataFrame](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/ListOfArraysToDataFrame.png)\n",
    "\n",
    "### Step 10: Create a list of paths\n",
    "We will create a list of paths to the images in all three folders in 'Black tea fermentation dataset', i.e. 'fermented tea', 'overfermented tea', and 'underfermented tea'.\n",
    "\n",
    "There are a few ways to do it, but ultimately you want a list containing 6,000 paths to each of the images in the folders, i.e. each string in the list should end with a \".png\".\n",
    "\n",
    "<strong>Hint: Google \"get list of all files in directory python\"</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Create a list of paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Loop through each path and repeat Steps 5-9\n",
    "Now that you have a list of paths, you can now create a list containing the normalized frequency of the LBP for each image. \n",
    "\n",
    "In summary, you will need to:\n",
    "1. Create two empty lists:\n",
    "    - one list to store the normalized frequency of LBP\n",
    "    - one list to store the labels of the tea. We will follow the same classes as Part III Step 4\n",
    "2. Use a for loop to loop through the list of path\n",
    "3. In each loop:\n",
    "    - append the corresponding label into the list of labels\n",
    "    - convert the image into greyscale\n",
    "    - extract the local binary pattern values from the greyscale image\n",
    "    - flatten the LBP array\n",
    "    - use numpy.histogram() to extract the frequency of the 20 bins\n",
    "    - normalize the frequency by dividing the array with the max value in the array\n",
    "    - append the resulting normalized array into the list of arrays\n",
    "\n",
    "#### Sanity check\n",
    "1. The first item in your list of arrays is an array of length 20.\n",
    "2. The first item in your list of labels is the label that corresponds to your list of image paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Get the LBPs for all of your images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Turn the list of arrays into a DataFrame\n",
    "Let's turn the list of arrays into a DataFrame.\n",
    "\n",
    "Your resulting DataFrame should have 6,000 rows and 20 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Turn the list of arrays into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Add a new column named 'label'\n",
    "We'll also add a new column named 'label' using the list of labels that you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Add a column called 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Export your DataFrame as a CSV in your Google Drive\n",
    "Your DataFrame should now have:\n",
    "1. 6,000 rows\n",
    "2. 21 columns\n",
    "\n",
    "Export the DataFrame you prepared into the same folder as your other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Export your DataFrame as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Part IV\n",
    "There we go, we've successfully extracted the local binary patterns of the images in your dataset and exported the DataFrame into a CSV file. \n",
    "\n",
    "Next up in Part V, we will use this CSV for our machine learning to classify the LBP into the different tea fermentation levels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
